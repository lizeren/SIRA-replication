{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88RmonGDYt3T",
        "outputId": "bd35422a-91a0-44fb-e73f-9b8060383672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/SIRA\n",
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/     \u001b[01;34mpytorch_version\u001b[0m/  requirements.gdoc\n",
            "\u001b[01;34mpreprocess\u001b[0m/  README.md         requirements.txt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/SIRA\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uaPmt7eKYv1e",
        "outputId": "efbbf7c7-13e3-458f-a215-afb598788282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting chinese-whispers==0.7.4\n",
            "  Downloading chinese_whispers-0.7.4-py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: networkx<3.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from chinese-whispers==0.7.4) (2.6.3)\n",
            "Installing collected packages: chinese-whispers\n",
            "Successfully installed chinese-whispers-0.7.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/MartinoMensio/spacy-universal-sentence-encoder/releases/download/v0.4.3/en_use_md-0.4.3.tar.gz\n",
            "  Downloading https://github.com/MartinoMensio/spacy-universal-sentence-encoder/releases/download/v0.4.3/en_use_md-0.4.3.tar.gz (24 kB)\n",
            "Collecting spacy<3.1.0,>=3.0.3\n",
            "  Downloading spacy-3.0.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 16.4 MB/s \n",
            "\u001b[?25hCollecting spacy_universal_sentence_encoder>=0.4.3\n",
            "  Downloading spacy_universal_sentence_encoder-0.4.5.tar.gz (13 kB)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.0.8)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.23.0)\n",
            "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp38-cp38-manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.7 MB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (0.7.9)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (3.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (57.4.0)\n",
            "Collecting thinc<8.1.0,>=8.0.3\n",
            "  Downloading thinc-8.0.17-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.4.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (3.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (1.0.9)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (1.21.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (4.64.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (1.24.3)\n",
            "Requirement already satisfied: tensorflow<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.9.2)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (from spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.12)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.1.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.9.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.50.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.15.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.1.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (14.0.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.19.6)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.28.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.4.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy_universal_sentence_encoder>=0.4.3->en-use-md==0.4.3) (3.2.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.1.0,>=3.0.3->en-use-md==0.4.3) (2.0.1)\n",
            "Building wheels for collected packages: en-use-md, spacy-universal-sentence-encoder\n",
            "  Building wheel for en-use-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-use-md: filename=en_use_md-0.4.3-py3-none-any.whl size=24372 sha256=d854f6d22fa2dda32d8d92f77b4f6ff70e0944d840cb80dcac86c3e7b2e44e40\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/33/12/6e08cf928d0a718b31c5e775884a538731587bd1b7add290d2\n",
            "  Building wheel for spacy-universal-sentence-encoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-universal-sentence-encoder: filename=spacy_universal_sentence_encoder-0.4.5-py3-none-any.whl size=15810 sha256=dbcf6b7cfc9ebcbfabc25bc08c5cd2244b432a77153a0eaa217eb1388f4caa3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/31/fb/b51e4633c73d97b8cd2244832c126acfd45519720d5571930e\n",
            "Successfully built en-use-md spacy-universal-sentence-encoder\n",
            "Installing collected packages: typer, pydantic, thinc, spacy, spacy-universal-sentence-encoder, en-use-md\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.2\n",
            "    Uninstalling pydantic-1.10.2:\n",
            "      Successfully uninstalled pydantic-1.10.2\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 8.1.5\n",
            "    Uninstalling thinc-8.1.5:\n",
            "      Successfully uninstalled thinc-8.1.5\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.4.3\n",
            "    Uninstalling spacy-3.4.3:\n",
            "      Successfully uninstalled spacy-3.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.0.8 which is incompatible.\u001b[0m\n",
            "Successfully installed en-use-md-0.4.3 pydantic-1.8.2 spacy-3.0.8 spacy-universal-sentence-encoder-0.4.5 thinc-8.0.17 typer-0.3.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting spacy-universal-sentence-encoder==0.4.3\n",
            "  Downloading spacy_universal_sentence_encoder-0.4.3.tar.gz (13 kB)\n",
            "Requirement already satisfied: tensorflow<3.0.0,>=2.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy-universal-sentence-encoder==0.4.3) (2.9.2)\n",
            "Requirement already satisfied: spacy<4.0.0,>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy-universal-sentence-encoder==0.4.3) (3.0.8)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.8/dist-packages (from spacy-universal-sentence-encoder==0.4.3) (0.12.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (3.0.10)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (0.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.11.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.0.8)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (3.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.4.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (1.21.6)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (0.3.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (1.8.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (0.10.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (4.64.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (0.7.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (8.0.17)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.0.7)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (5.2.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (3.0.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.19.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.1.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.28.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (2.9.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (2.1.1)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (2.9.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.50.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.38.4)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (2.14.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.6.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.4.0->spacy-universal-sentence-encoder==0.4.3) (3.2.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.0->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<4.0.0,>=3.0.0->spacy-universal-sentence-encoder==0.4.3) (2.0.1)\n",
            "Building wheels for collected packages: spacy-universal-sentence-encoder\n",
            "  Building wheel for spacy-universal-sentence-encoder (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for spacy-universal-sentence-encoder: filename=spacy_universal_sentence_encoder-0.4.3-py3-none-any.whl size=14763 sha256=8dd2455af88063fdb95ac88664d7ef34c80865c4b689b2befca5f20295d78a48\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/47/ed/4dc63e35260b4c75fea227ab0bcd448d55378b5da1de8c3394\n",
            "Successfully built spacy-universal-sentence-encoder\n",
            "Installing collected packages: spacy-universal-sentence-encoder\n",
            "  Attempting uninstall: spacy-universal-sentence-encoder\n",
            "    Found existing installation: spacy-universal-sentence-encoder 0.4.5\n",
            "    Uninstalling spacy-universal-sentence-encoder-0.4.5:\n",
            "      Successfully uninstalled spacy-universal-sentence-encoder-0.4.5\n",
            "Successfully installed spacy-universal-sentence-encoder-0.4.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.5.0\n",
            "  Downloading tensorflow-2.5.0-cp38-cp38-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 41 kB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.4.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.19.6)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.38.4)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp38-cp38-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 69.4 MB/s \n",
            "\u001b[?25hCollecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp38-cp38-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 65.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.1.2)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.3.0)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (3.1.0)\n",
            "Collecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (0.2.0)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.12)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (2.9.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.5.0) (1.15.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 77.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 74.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard~=2.5->tensorflow==2.5.0) (2.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.0) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.5->tensorflow==2.5.0) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5.0) (3.2.2)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=83eb556e4ffa3b37ef998018bb61fb19aa59bcb8494af5e1cd2c05722e86f77f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=72352 sha256=f5df735d8bb632ad8551b64c888f838c03c9a50eb2f8cf088a548b07705a0b0a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: numpy, grpcio, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, keras-nightly, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.50.0\n",
            "    Uninstalling grpcio-1.50.0:\n",
            "      Successfully uninstalled grpcio-1.50.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.3.0\n",
            "    Uninstalling absl-py-1.3.0:\n",
            "      Successfully uninstalled absl-py-1.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.1\n",
            "    Uninstalling termcolor-2.1.1:\n",
            "      Successfully uninstalled termcolor-2.1.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.2.2 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "grpcio-status 1.48.2 requires grpcio>=1.48.2, but you have grpcio 1.34.1 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.0.8 which is incompatible.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 tensorflow-2.5.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp38-cp38-linux_x86_64.whl (708.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 708.1 MB 12 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.7.0%2Bcu101-cp38-cp38-linux_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 49.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.8/dist-packages (from torchvision==0.7.0+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.1+cu113\n",
            "    Uninstalling torchvision-0.13.1+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.6.0+cu101 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.6.0+cu101 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.6.0+cu101 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.7.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0+cu101 torchvision-0.7.0+cu101\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.0.0\n",
            "  Downloading transformers-4.0.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (4.64.1)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp38-cp38-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.0.0) (2022.6.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 62.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->transformers==4.0.0) (3.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.0.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.0.0) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers==4.0.0) (1.2.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=17d1a4a75d6f91b7eeaaa93d5a65b2ee5232bb5d68fb99afcaa57667a8879336\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/ab/9b/c15899bf659ba74f623ac776e861cf2eb8608c1825ddec66a4\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.53 tokenizers-0.9.4 transformers-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chinese-whispers==0.7.4\n",
        "#!pip install en-use-md @ https://github.com/MartinoMensio/spacy-universal-sentence-encoder/releases/download/v0.4.3/en_use_md-0.4.3.tar.gz\n",
        "!pip install https://github.com/MartinoMensio/spacy-universal-sentence-encoder/releases/download/v0.4.3/en_use_md-0.4.3.tar.gz\n",
        "!pip install spacy-universal-sentence-encoder==0.4.3\n",
        "!pip install tensorflow==2.5.0\n",
        "!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install transformers==4.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNJiZfSRbFnv",
        "outputId": "23d1f7cd-4ae5-43d2-cefc-84780c4f55ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdataset\u001b[0m/     \u001b[01;34mpytorch_version\u001b[0m/  requirements.gdoc\n",
            "\u001b[01;34mpreprocess\u001b[0m/  README.md         requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSvrZT_OhRfn",
        "outputId": "957b7c78-a260-46ce-ec67-5c2ef4650222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA/pytorch_version\n"
          ]
        }
      ],
      "source": [
        "%cd pytorch_version/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIHrcd3Gh6sj",
        "outputId": "2c058a67-7d7d-49cb-aa6f-f9bba1c6471a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 15.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.22-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 26.9 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 11.4 MB/s \n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.22\n",
            "  Downloading botocore-1.29.22-py3-none-any.whl (10.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.2 MB 59.8 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.22->boto3) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 78.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.22->boto3) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.13 which is incompatible.\n",
            "google-cloud-bigquery 3.3.6 requires grpcio<2.0dev,>=1.47.0, but you have grpcio 1.34.1 which is incompatible.\n",
            "fastai 2.7.10 requires torch<1.14,>=1.7, but you have torch 1.6.0+cu101 which is incompatible.\n",
            "fastai 2.7.10 requires torchvision>=0.8.2, but you have torchvision 0.7.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.26.22 botocore-1.29.22 jmespath-1.0.1 s3transfer-0.6.0 urllib3-1.26.13\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece\n",
        "!pip install boto3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l_YMw0qhWLD",
        "outputId": "b09064a6-f8e0-4943-d173-9835cdd3b4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA\n",
            "/content/drive/MyDrive/SIRA/pytorch_version\n",
            "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
            "2022-12-04 03:44:19.115894: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "12/04/2022 03:45:07 - WARNING - root -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "100% 3/3 [00:00<00:00, 16469.78it/s]\n",
            "100% 10/10 [00:00<00:00, 252668.92it/s]\n",
            "100% 6/6 [00:00<00:00, 195083.91it/s]\n",
            "3it [00:00, 116508.44it/s]\n",
            "100% 3/3 [00:00<00:00, 122164.19it/s]\n",
            "10it [00:00, 338250.32it/s]\n",
            "100% 10/10 [00:00<00:00, 377865.23it/s]\n",
            "6it [00:00, 226719.14it/s]\n",
            "100% 6/6 [00:00<00:00, 246723.76it/s]\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.configuration_utils -   loading configuration file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/config.json\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.configuration_utils -   Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"ext_cate_size\": 3,\n",
            "  \"ext_senti_size\": 10,\n",
            "  \"feature_size\": 10,\n",
            "  \"finetuning_task\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 7,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"transformers_version\": \"4.6.0.dev0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   Model name '/content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased). Assuming '/content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased' is a path or url to a directory containing tokenizer files.\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   Didn't find file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/added_tokens.json. We won't load it.\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   Didn't find file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/special_tokens_map.json. We won't load it.\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   loading file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/vocab.txt\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   loading file None\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   loading file None\n",
            "12/04/2022 03:45:10 - INFO - models.transformers.tokenization_utils -   loading file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/tokenizer_config.json\n",
            "12/04/2022 03:45:11 - INFO - models.transformers.modeling_utils -   loading weights file /content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased/pytorch_model.bin\n",
            "12/04/2022 03:45:22 - INFO - models.transformers.modeling_utils -   Weights of BertCrfForNer not initialized from pretrained model: ['ext_cate_embedding.weight', 'ext_senti_embedding.weight', 'classifier.weight', 'classifier.bias', 'crf.start_transitions', 'crf.end_transitions', 'crf.transitions']\n",
            "12/04/2022 03:45:22 - INFO - models.transformers.modeling_utils -   Weights from pretrained model not used in BertCrfForNer: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "12/04/2022 03:45:25 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', cache_dir='', config_name='', crf_learning_rate=5e-05, data_dir='/content/drive/MyDrive/SIRA/pytorch_version/CLUEdatasets/cluener/label', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=True, do_predict=True, do_train=False, eval_all_checkpoints=False, eval_max_seq_length=128, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, id2label={0: 'X', 1: 'B-name', 2: 'I-name', 3: 'S-name', 4: 'O', 5: '[START]', 6: '[END]'}, label2id={'X': 0, 'B-name': 1, 'I-name': 2, 'S-name': 3, 'O': 4, '[START]': 5, '[END]': 6}, learning_rate=0.0001, local_rank=-1, logging_steps=448, loss_type='ce', markup='bios', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/content/drive/MyDrive/SIRA/pytorch_version/prev_trained_model/bert-base_uncased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=5.0, output_dir='/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label', overwrite_cache=True, overwrite_output_dir=True, per_gpu_eval_batch_size=32, per_gpu_train_batch_size=32, predict_checkpoints=0, save_steps=448, seed=42, server_ip='', server_port='', task_name='cluener', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)\n",
            "12/04/2022 03:45:25 - INFO - root -   Predict the following checkpoints: ['/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label']\n",
            "12/04/2022 03:45:25 - INFO - models.transformers.modeling_utils -   loading weights file /content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label/pytorch_model.bin\n",
            "12/04/2022 03:45:38 - INFO - root -   Creating features from dataset file at /content/drive/MyDrive/SIRA/pytorch_version/CLUEdatasets/cluener/label\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   Writing example 0 of 8\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] not changing this until something is done about the most recent [UNK] [UNK] by far the worst of all [UNK] always [UNK] and [UNK] with the new feature where the camera always opens whenever you open a [UNK] just terrible now after [UNK] last update i [UNK] see any of my [UNK] even if i create a new [UNK] still [UNK] [UNK] [UNK] [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: not changing this until something is done about the most recent update! it's by far the worst of all updates!! always laggy and what's with the new feature where the camera always opens whenever you open a chat?? just terrible now after august's last update i can't see any of my shortcuts even if i create a new one, still can't seeuse wow!\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 65\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: instagram   app_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: -3   senti_ids: 2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 2025 5278 2023 2127 2242 2003 2589 2055 1996 2087 3522 100 100 2011 2521 1996 5409 1997 2035 100 2467 100 1998 100 2007 1996 2047 3444 2073 1996 4950 2467 7480 7188 2017 2330 1037 100 2074 6659 2085 2044 100 2197 10651 1045 100 2156 2151 1997 2026 100 2130 2065 1045 3443 1037 2047 100 2145 100 100 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] [UNK] is a creative app but [UNK] rating it with 4 star because there should be a download option for voice notes that we receive or sent and another there should be an option to star mark the particular text we sent or received other than that everything is good hope to see these features on [UNK] soon thanks [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: snapchat is a creative app but i'm rating it with 4 star because there should be a download option for voice notes that we receive or sent and another there should be an option to star mark the particular text we sent or received other than that everything is good hope to see these features on snapchat soon thanks\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 61\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: snapchat   app_ids: 1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: 3   senti_ids: 7\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 100 2003 1037 5541 10439 2021 100 5790 2009 2007 1018 2732 2138 2045 2323 2022 1037 8816 5724 2005 2376 3964 2008 2057 4374 2030 2741 1998 2178 2045 2323 2022 2019 5724 2000 2732 2928 1996 3327 3793 2057 2741 2030 2363 2060 2084 2008 2673 2003 2204 3246 2000 2156 2122 2838 2006 100 2574 4283 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 2 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] i used to really love this app but recently it started [UNK] a lot it started not sending me any [UNK] at all the only thing i can do is [UNK] and [UNK] the app please fix that and [UNK] give 5 [UNK] [UNK] [UNK] been fixed [UNK] now so [UNK] giving 5 stars [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: i used to really love this app but recently it started glitching a lot it started not sending me any notifications at all the only thing i can do is uninstall and reinstall the app please fix that and i'll give 5 stars! edit: it's been fixed (for now so i'm giving 5 stars\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 56\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: instagram   app_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: 4   senti_ids: 8\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 1045 2109 2000 2428 2293 2023 10439 2021 3728 2009 2318 100 1037 2843 2009 2318 2025 6016 2033 2151 100 2012 2035 1996 2069 2518 1045 2064 2079 2003 100 1998 100 1996 10439 3531 8081 2008 1998 100 2507 1019 100 100 100 2042 4964 100 2085 2061 100 3228 1019 3340 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-3\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] i use this app to video chat with my so who lives a few states over my only wish is that there was a way to implement an option to stay in call for 5 minutes after another person ends the call i had to end the call one morning to pick up another [UNK] but was sad that i [UNK] able to get back into the call with them because of my early necessary call we sometimes sleep on calls as i have severe separation anxiety and [UNK] just disappointing that we [UNK] jump out and jump back in for a call have [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: i use this app to video chat with my so who lives a few states over my only wish is that there was a way to implement an option to stay in call for 5 minutes after another person ends the call i had to end the call one morning to pick up another call, but was sad that i wasn't able to get back into the call with them because of my early necessary call we sometimes sleep on calls as i have severe separation anxiety and it's just disappointing that we can't jump out and jump back in for a call have\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 106\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: snapchat   app_ids: 1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: -4   senti_ids: 1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 1045 2224 2023 10439 2000 2678 11834 2007 2026 2061 2040 3268 1037 2261 2163 2058 2026 2069 4299 2003 2008 2045 2001 1037 2126 2000 10408 2019 5724 2000 2994 1999 2655 2005 1019 2781 2044 2178 2711 4515 1996 2655 1045 2018 2000 2203 1996 2655 2028 2851 2000 4060 2039 2178 100 2021 2001 6517 2008 1045 100 2583 2000 2131 2067 2046 1996 2655 2007 2068 2138 1997 2026 2220 4072 2655 2057 2823 3637 2006 4455 2004 1045 2031 5729 8745 10089 1998 100 2074 15640 2008 2057 100 5376 2041 1998 5376 2067 1999 2005 1037 2655 2031 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 4 4 1 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-4\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] i been running into some issues where it it only send messages via [UNK] and not my mobile [UNK] which i find a bit odd no way to change back your avatar from 3d to 2d i miss my old avatar and would very much like it back you should have at least made it an option to switch [UNK] them in the settings it would have been nice to have the option [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: i been running into some issues where it it only send messages via wifi and not my mobile data, which i find a bit odd no way to change back your avatar from 3d to 2d i miss my old avatar and would very much like it back you should have at least made it an option to switch inbetween them in the settings it would have been nice to have the option\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 75\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: snapchat   app_ids: 1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: -2   senti_ids: 3\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 1045 2042 2770 2046 2070 3314 2073 2009 2009 2069 4604 7696 3081 100 1998 2025 2026 4684 100 2029 1045 2424 1037 2978 5976 2053 2126 2000 2689 2067 2115 22128 2013 7605 2000 14134 1045 3335 2026 2214 22128 1998 2052 2200 2172 2066 2009 2067 2017 2323 2031 2012 2560 2081 2009 2019 5724 2000 6942 100 2068 1999 1996 10906 2009 2052 2031 2042 3835 2000 2031 1996 5724 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-5\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] the ads get in my [UNK] i [UNK] understand their purpose except to [UNK] me they move around as i am [UNK] them causing me to [UNK] my actual emails selecting bulk emails to [UNK] [UNK] that great in the app i [UNK] edit or [UNK] as much when creating emails in the app for a world class tech [UNK] you would think the email app would be much less annoying [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: the ads get in my way, i don't understand their purpose except to annoy me they move around as i am deleting them causing me to delete my actual emails selecting bulk emails to delete isn't that great in the app i cant edit or personalize as much when creating emails in the app for a world class tech company, you would think the email app would be much less annoying\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 73\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: communication   cate_ids: 2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: gmail   app_ids: 5\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: -3   senti_ids: 2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 1996 14997 2131 1999 2026 100 1045 100 3305 2037 3800 3272 2000 100 2033 2027 2693 2105 2004 1045 2572 100 2068 4786 2033 2000 100 2026 5025 22028 17739 9625 22028 2000 100 100 2008 2307 1999 1996 10439 1045 100 10086 2030 100 2004 2172 2043 4526 22028 1999 1996 10439 2005 1037 2088 2465 6627 100 2017 2052 2228 1996 10373 10439 2052 2022 2172 2625 15703 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 3 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-6\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] literally useless i never receive [UNK] for any of my accounts unless the app is already open [UNK] filter is a little too powerful and filters out [UNK] [UNK] and appointment [UNK] that i would actually love to see and i [UNK] even load my [UNK] folder in app so i need to either log in on my mobile browser [UNK] or use a different email app [UNK] i will be doing going forward [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: literally useless i never receive notifications for any of my accounts unless the app is already open spam filter is a little too powerful and filters out etransfers, receipts, and appointment confirmations that i would actually love to see and i can't even load my spam folder in app so i need to either log in on my mobile browser (annoying or use a different email app (what i will be doing going forward\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 76\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: communication   cate_ids: 2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: gmail   app_ids: 5\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: -3   senti_ids: 2\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 6719 11809 1045 2196 4374 100 2005 2151 1997 2026 6115 4983 1996 10439 2003 2525 2330 100 11307 2003 1037 2210 2205 3928 1998 17736 2041 100 100 1998 6098 100 2008 1045 2052 2941 2293 2000 2156 1998 1045 100 2130 7170 2026 100 19622 1999 10439 2061 1045 2342 2000 2593 8833 1999 2006 2026 4684 16602 100 2030 2224 1037 2367 10373 10439 100 1045 2097 2022 2725 2183 2830 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 4 1 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   *** Example ***\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   guid: dev-7\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   tokens: [CLS] [UNK] still [UNK] log into app says there is an error and to clear cache that does nothing please [UNK] just installed app after a phone reset now i [UNK] log in input my [UNK] hit the log in button and the app closes open to the log on [UNK] same results everything worked great this [UNK] now it [UNK] [SEP]\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   text: update, still can't log into app says there is an error and to clear cache that does nothing please help! just installed app after a phone reset now i can't log in input my credentials, hit the log in button and the app closes open to the log on screen, same results everything worked great this morning, now it doesn't\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   length: 62\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   cate: social   cate_ids: 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   app: snapchat   app_ids: 1\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   senti_score: 3   senti_ids: 7\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_ids: 101 100 2145 100 8833 2046 10439 2758 2045 2003 2019 7561 1998 2000 3154 17053 2008 2515 2498 3531 100 2074 5361 10439 2044 1037 3042 25141 2085 1045 100 8833 1999 7953 2026 100 2718 1996 8833 1999 6462 1998 1996 10439 14572 2330 2000 1996 8833 2006 100 2168 3463 2673 2499 2307 2023 100 2085 2009 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - processors.ner_seq -   label_ids: 4 4 4 1 2 2 2 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "12/04/2022 03:45:38 - INFO - root -   Saving features into cached file /content/drive/MyDrive/SIRA/pytorch_version/CLUEdatasets/cluener/label/cached_crf-dev_bert-base_uncased_128_cluener\n",
            "8\n",
            "12/04/2022 03:45:40 - INFO - root -   ***** Running prediction  *****\n",
            "12/04/2022 03:45:40 - INFO - root -     Num examples = 8\n",
            "12/04/2022 03:45:40 - INFO - root -     Batch size = 1\n",
            "[Predicting] 8/8 [==============================] 25.6ms/step12/04/2022 03:45:40 - INFO - root -   \n",
            "\n",
            "{}\n",
            "Traceback (most recent call last):\n",
            "  File \"run_ner_crf.py\", line 544, in <module>\n",
            "    acc, recall = main()\n",
            "  File \"run_ner_crf.py\", line 540, in main\n",
            "    return results['acc'], results['recall']\n",
            "KeyError: 'acc'\n"
          ]
        }
      ],
      "source": [
        "%cd ..\n",
        "%cd pytorch_version\n",
        "!bash run_ner_crf.sh\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJ8xki13_yFI",
        "outputId": "0ebe41d8-41e1-49c6-a95e-64a86f247cc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'SIRA'\n",
            "/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label\n",
            "bert-cluener-2022-12-01-21_38_44.log  bert-cluener-2022-12-02-04_45_58.log\n",
            "bert-cluener-2022-12-01-21_45_40.log  bert-cluener-2022-12-02-04_50_54.log\n",
            "bert-cluener-2022-12-01-21_47_12.log  bert-cluener-2022-12-02-04_52_54.log\n",
            "bert-cluener-2022-12-01-21_59_16.log  bert-cluener-2022-12-03-23_59_55.log\n",
            "bert-cluener-2022-12-01-22_01_17.log  \u001b[0m\u001b[01;34mcheckpoint-1344\u001b[0m/\n",
            "bert-cluener-2022-12-01-22_52_17.log  \u001b[01;34mcheckpoint-1792\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_29_41.log  \u001b[01;34mcheckpoint-2240\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_34_16.log  \u001b[01;34mcheckpoint-448\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_35_48.log  \u001b[01;34mcheckpoint-896\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_37_47.log  communication.csv\n",
            "bert-cluener-2022-12-02-04_38_52.log  config.json\n",
            "bert-cluener-2022-12-02-04_39_38.log  eval_results.txt\n",
            "bert-cluener-2022-12-02-04_40_27.log  pytorch_model.bin\n",
            "bert-cluener-2022-12-02-04_41_21.log  res.csv\n",
            "bert-cluener-2022-12-02-04_41_46.log  social.csv\n",
            "bert-cluener-2022-12-02-04_43_08.log  test_prediction.json\n",
            "bert-cluener-2022-12-02-04_43_27.log  test_submit.json\n",
            "bert-cluener-2022-12-02-04_43_57.log  training_args.bin\n",
            "bert-cluener-2022-12-02-04_45_23.log  vocab.txt\n",
            "[Errno 2] No such file or directory: 'preprocess'\n",
            "/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label\n"
          ]
        }
      ],
      "source": [
        "%cd SIRA\n",
        "%ls\n",
        "%cd preprocess\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heXMTd4tkeUF",
        "outputId": "b60ceba8-3c94-4b1f-ba25-8f0a515a96bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.8/dist-packages (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3==1.26.13 in /usr/local/lib/python3.8/dist-packages (1.26.13)\n"
          ]
        }
      ],
      "source": [
        "!pip install chardet==3.0.4\n",
        "!pip install urllib3==1.26.13"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsEvEbxnxPNN",
        "outputId": "3b106b5e-22c3-4488-fb81-25b2a207f0c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUQP8ZE9_4pS",
        "outputId": "9c56c007-0a9b-45ba-84a3-56bd2dd7802b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-04 06:11:28.181037: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "/usr/local/lib/python3.8/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (3.0.4) doesn't match a supported version!\n",
            "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
            "2022-12-04 06:11:31.114312: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2022-12-04 06:11:31.114498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.115100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-12-04 06:11:31.115147: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-12-04 06:11:31.115234: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2022-12-04 06:11:31.115271: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2022-12-04 06:11:31.115308: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2022-12-04 06:11:31.115344: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2022-12-04 06:11:31.115414: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
            "2022-12-04 06:11:31.115435: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2022-12-04 06:11:31.115700: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2022-12-04 06:11:31.115813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.116408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.116926: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2022-12-04 06:11:31.117139: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-04 06:11:31.117371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.117907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2022-12-04 06:11:31.117973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.118513: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.119012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2022-12-04 06:11:31.119074: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2022-12-04 06:11:31.786886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-12-04 06:11:31.786947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2022-12-04 06:11:31.786969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2022-12-04 06:11:31.787113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.787744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.788307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-12-04 06:11:31.788827: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-12-04 06:11:31.788873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13777 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2022-12-04 06:11:33.802285: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
            "2022-12-04 06:11:33.935802: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2000160000 Hz\n",
            "0it [00:00, ?it/s]2022-12-04 06:11:35.293912: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2022-12-04 06:11:35.721914: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "8it [00:00, 11.50it/s]\n",
            "voice notes, 5\n",
            "video chat, 4\n",
            "log into app; log in, 3\n",
            "video talk, 4\n",
            "voice message, 5\n",
            "see any of my shortcuts, 9\n",
            "sending me any notifications at all, 7\n",
            "notifications, 7\n",
            "shortcuts, 9\n",
            "All the groups:\n",
            "{'5': 'voice notes', '4': 'video chat', '3': 'log into app; log in', '9': 'see any of my shortcuts', '7': 'sending me any notifications at all'}\n",
            "label:\n",
            "{'voice notes': '5', 'video chat': '4', 'log into app; log in': '3', 'video talk': '4', 'voice message': '5', 'see any of my shortcuts': '9', 'sending me any notifications at all': '7', 'notifications': '7', 'shortcuts': '9'}\n",
            "domain_docs:\n",
            "{'snapchat': ['voice notes', 'video chat', 'log into app; log in', 'video talk', 'voice message'], 'instagram': ['see any of my shortcuts', 'sending me any notifications at all', 'notifications', 'shortcuts']}\n",
            "percentage:\n",
            "{'snapchat': {'5': 2, '4': 2, '3': 1}, 'instagram': {'9': 2, '7': 2}}\n",
            "clean_feature:\n",
            "['voice notes', 'video chat', 'log into app; log in', 'see any of my shortcuts', 'sending me any notifications at all']\n",
            "clean_name:\n",
            "['snapchat', 'instagram']\n",
            "Final Result:\n",
            "{'snapchat': {'voice notes': 2, 'video chat': 2, 'log into app; log in': 1}, 'instagram': {'see any of my shortcuts': 2, 'sending me any notifications at all': 2}}\n"
          ]
        }
      ],
      "source": [
        "!python3 clustering.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_SwGpSc_clR",
        "outputId": "03288505-bf87-4013-efaa-2c8155a8c634"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clustering.py  __init__.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pytorch_version/outputs/cluener_output/bert/label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uPiLvzU_fk6",
        "outputId": "1867271f-dbd7-4fd2-bce0-aeffb44ce62d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat = ['communication' , 'social']\n",
        "dict_cat ={'gmail':'communication','snapchat':'social','instagram': 'social'}\n",
        "result_social = {}\n",
        "result_communication = {}\n",
        "import csv\n",
        "with open('res.csv', newline='') as fp:\n",
        "    spamreader = csv.reader(fp)\n",
        "    for row in spamreader:\n",
        "        if dict_cat[row[0]] == cat[1] and row[len(row) - 1]:\n",
        "          if row[0] not in result_social:\n",
        "            result_social[row[0]] = [row[4]]\n",
        "          else:\n",
        "            result_social[row[0]].append(row[4])\n",
        "        elif dict_cat[row[0]] == cat[0] and row[len(row) - 1]:\n",
        "          if row[0] not in result_communication:\n",
        "            result_communication[row[0]] = [row[4]]\n",
        "          else:\n",
        "            result_communication[row[0]].append(row[4])\n",
        "\n",
        "print (result_communication)\n",
        "print (result_social)\n",
        "\n",
        "    \n",
        "# writing to csv file \n",
        "file = open('social.csv', 'w',newline='')\n",
        "write = csv.writer(file)\n",
        "for item in result_social:\n",
        "    write.writerow([item]+result_social[item])\n",
        "file.close()\n",
        "  \n",
        "file = open('communication.csv', 'w',newline='')\n",
        "write = csv.writer(file)\n",
        "for item in result_communication:\n",
        "    write.writerow([item]+result_communication[item])\n",
        "file.close()"
      ],
      "metadata": {
        "id": "HNVJIDcQ_uT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29daa915-6bc2-4d7a-8103-d6903ba33baa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'gmail': ['selecting bulk emails; creating emails', 'receive notifications for any of my accounts']}\n",
            "{'instagram': ['see any of my shortcuts', 'sending me any notifications at all'], 'snapchat': ['voice notes', 'video chat', 'log into app; log in']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../preprocess\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7_1HoopBidK",
        "outputId": "1203ec20-48ab-4910-b2e9-4cabd00f52c2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA/preprocess\n",
            "clustering.py  __init__.py  \u001b[0m\u001b[01;34m__pycache__\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../pytorch_version/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A10cQmNyU-xJ",
        "outputId": "faa3e5af-f7f1-46a0-a6f5-1f99307e1088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '../pytorch_version/'\n",
            "/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QND9xTR7dI_Y",
        "outputId": "2e01fa74-b6ab-41bd-f08f-40380b0694c9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert-cluener-2022-12-01-21_38_44.log  bert-cluener-2022-12-02-04_45_58.log\n",
            "bert-cluener-2022-12-01-21_45_40.log  bert-cluener-2022-12-02-04_50_54.log\n",
            "bert-cluener-2022-12-01-21_47_12.log  bert-cluener-2022-12-02-04_52_54.log\n",
            "bert-cluener-2022-12-01-21_59_16.log  bert-cluener-2022-12-03-23_59_55.log\n",
            "bert-cluener-2022-12-01-22_01_17.log  \u001b[0m\u001b[01;34mcheckpoint-1344\u001b[0m/\n",
            "bert-cluener-2022-12-01-22_52_17.log  \u001b[01;34mcheckpoint-1792\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_29_41.log  \u001b[01;34mcheckpoint-2240\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_34_16.log  \u001b[01;34mcheckpoint-448\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_35_48.log  \u001b[01;34mcheckpoint-896\u001b[0m/\n",
            "bert-cluener-2022-12-02-04_37_47.log  communication.csv\n",
            "bert-cluener-2022-12-02-04_38_52.log  config.json\n",
            "bert-cluener-2022-12-02-04_39_38.log  eval_results.txt\n",
            "bert-cluener-2022-12-02-04_40_27.log  pytorch_model.bin\n",
            "bert-cluener-2022-12-02-04_41_21.log  res.csv\n",
            "bert-cluener-2022-12-02-04_41_46.log  social.csv\n",
            "bert-cluener-2022-12-02-04_43_08.log  test_prediction.json\n",
            "bert-cluener-2022-12-02-04_43_27.log  test_submit.json\n",
            "bert-cluener-2022-12-02-04_43_57.log  training_args.bin\n",
            "bert-cluener-2022-12-02-04_45_23.log  vocab.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd outputs/cluener_output/bert/label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-s63UOBdNwT",
        "outputId": "99d7f741-dedf-407e-b4aa-ab14ba37ba91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA/pytorch_version/outputs/cluener_output/bert/label\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../../../..\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGTxy4Rndeip",
        "outputId": "ed4a4247-5c25-4720-c5d5-548ed972eb73"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/SIRA/pytorch_version\n",
            "Anaconda3-2022.10-Linux-x86_64.sh  \u001b[0m\u001b[01;34mlosses\u001b[0m/              \u001b[01;34mprocessors\u001b[0m/\n",
            "\u001b[01;34mcallback\u001b[0m/                          \u001b[01;34mmetrics\u001b[0m/             run_ner_crf.py\n",
            "\u001b[01;34mCLUEdatasets\u001b[0m/                      \u001b[01;34mmodels\u001b[0m/              run_ner_crf.sh\n",
            "\u001b[01;34mext_feature\u001b[0m/                       \u001b[01;34moutputs\u001b[0m/             \u001b[01;34mscripts\u001b[0m/\n",
            "__init__.py                        \u001b[01;34mprev_trained_model\u001b[0m/  \u001b[01;34mtools\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C5OCxfg0dpNP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}